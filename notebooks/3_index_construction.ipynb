{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rongxuan-Zhou/CS6120_project/blob/main/notebooks/3_index_construction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Environment Setup\n",
        "!pip install -q faiss-cpu sentence-transformers nltk\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "PROJECT_PATH = \"/content/drive/MyDrive/CS6120_project\"\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "# GPU detection\n",
        "import torch\n",
        "print(f\"Available GPU: {torch.cuda.is_available()}\")\n",
        "print(\"Note: Using CPU version of FAISS for compatibility\")\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(\"models/indexes\", exist_ok=True)"
      ],
      "metadata": {
        "id": "nkwnGva970ai",
        "outputId": "78ed7664-1bca-4fe7-c662-4a85cd9d4e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Available GPU: True\n",
            "Note: Using CPU version of FAISS for compatibility\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load fine-tuned SBERT model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# 加载微调过的模型\n",
        "model = SentenceTransformer(\"models/sbert_model\")\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Model loaded successfully: {model}\")\n",
        "\n",
        "# 显示模型架构信息\n",
        "print(f\"Model architecture: {model.get_sentence_embedding_dimension()}d embeddings\")"
      ],
      "metadata": {
        "id": "FA_LgAUT756Q",
        "outputId": "53d75a1d-1c8f-48cd-bd23-009b7c41e3c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully: SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
            "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Normalize()\n",
            ")\n",
            "Model architecture: 768d embeddings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Build FAISS index (based on src/index_builder.py)\n",
        "import faiss\n",
        "import numpy as np\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# 清理 GPU 缓存\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "with open(\"data/processed/combined.json\") as f:\n",
        "    data = json.load(f)\n",
        "    # 合并所有数据以创建更全面的索引\n",
        "    corpus = data[\"train\"] + data[\"val\"] + data[\"test\"]\n",
        "\n",
        "print(f\"Loaded {len(corpus)} documents\")\n",
        "\n",
        "# Batch encoding with timing\n",
        "print(\"Generating embeddings...\")\n",
        "start_time = time.time()\n",
        "batch_size = 128\n",
        "embeddings = []\n",
        "for i in tqdm(range(0, len(corpus), batch_size)):\n",
        "    batch = corpus[i:i+batch_size]\n",
        "    emb = model.encode(batch, show_progress_bar=False)\n",
        "    embeddings.append(emb)\n",
        "\n",
        "embeddings = np.vstack(embeddings)\n",
        "encoding_time = time.time() - start_time\n",
        "dimension = embeddings.shape[1]\n",
        "print(f\"Generated {len(embeddings)} embeddings of dimension {dimension}\")\n",
        "print(f\"Encoding completed in {encoding_time:.2f} seconds ({len(corpus)/encoding_time:.2f} docs/sec)\")\n",
        "\n",
        "# 归一化向量以便使用内积计算余弦相似度\n",
        "print(\"Normalizing vectors...\")\n",
        "faiss.normalize_L2(embeddings)\n",
        "\n",
        "# Create flat FAISS index (精确搜索)\n",
        "print(\"Building flat index...\")\n",
        "index_flat = faiss.IndexFlatIP(dimension)\n",
        "index_flat.add(embeddings)\n",
        "print(f\"Flat index built with {index_flat.ntotal} vectors\")\n",
        "\n",
        "# 创建 HNSW 索引（更快的检索）\n",
        "print(\"Building HNSW index...\")\n",
        "M = 16  # 每个节点的连接数\n",
        "ef_construction = 200  # 构建时的搜索宽度\n",
        "index_hnsw = faiss.IndexHNSWFlat(dimension, M)\n",
        "index_hnsw.hnsw.efConstruction = ef_construction\n",
        "index_hnsw.add(embeddings)\n",
        "print(f\"HNSW index built with {index_hnsw.ntotal} vectors\")\n",
        "\n",
        "# 创建 IVF-PQ 索引（更小的内存占用）\n",
        "print(\"Building IVF-PQ index...\")\n",
        "nlist = min(100, len(corpus) // 50)  # 聚类中心数\n",
        "m = 8  # 子向量数\n",
        "bits = 8  # 每个子向量的位数\n",
        "quantizer = faiss.IndexFlatL2(dimension)\n",
        "index_ivfpq = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, bits)\n",
        "index_ivfpq.train(embeddings)\n",
        "index_ivfpq.add(embeddings)\n",
        "print(f\"IVF-PQ index built with {index_ivfpq.ntotal} vectors\")\n",
        "\n",
        "# 保存向量维度信息，便于后续加载\n",
        "embedding_info = {\n",
        "    \"dimension\": dimension,\n",
        "    \"count\": len(embeddings),\n",
        "    \"corpus_size\": len(corpus)\n",
        "}\n",
        "\n",
        "with open(os.path.join(\"models/indexes\", \"embedding_info.json\"), 'w') as f:\n",
        "    json.dump(embedding_info, f)"
      ],
      "metadata": {
        "id": "emQqX8Qa8CqP",
        "outputId": "7609d753-0a38-4845-8be1-ed2d9379260a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Loaded 11000 documents\n",
            "Generating embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 86/86 [00:19<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 11000 embeddings of dimension 768\n",
            "Encoding completed in 19.68 seconds (559.02 docs/sec)\n",
            "Normalizing vectors...\n",
            "Building flat index...\n",
            "Flat index built with 11000 vectors\n",
            "Building HNSW index...\n",
            "HNSW index built with 11000 vectors\n",
            "Building IVF-PQ index...\n",
            "IVF-PQ index built with 11000 vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Test indexes with sample queries and measure performance\n",
        "import time\n",
        "\n",
        "test_queries = [\n",
        "    \"How does social media affect mental health?\",\n",
        "    \"Best programming languages to learn\",\n",
        "    \"Artificial intelligence applications\",\n",
        "    \"Climate change solutions and mitigation strategies\",\n",
        "    \"Nutrition advice for athletes performance\"\n",
        "]\n",
        "\n",
        "print(\"Testing indexes with sample queries...\")\n",
        "# 对测试查询进行编码\n",
        "query_embeddings = model.encode(test_queries)\n",
        "\n",
        "# 归一化查询向量\n",
        "faiss.normalize_L2(query_embeddings)\n",
        "\n",
        "# 设置返回结果数量\n",
        "k = 5\n",
        "\n",
        "# 性能测试变量\n",
        "num_runs = 5\n",
        "flat_times = []\n",
        "hnsw_times = []\n",
        "ivfpq_times = []\n",
        "\n",
        "# Flat 索引搜索（最精确但最慢）\n",
        "print(\"\\nFlat index search results:\")\n",
        "for _ in range(num_runs):\n",
        "    start = time.time()\n",
        "    D_flat, I_flat = index_flat.search(query_embeddings, k)\n",
        "    flat_times.append(time.time() - start)\n",
        "\n",
        "avg_flat_time = sum(flat_times) / len(flat_times)\n",
        "print(f\"Flat index average search time: {avg_flat_time*1000:.2f} ms\")\n",
        "\n",
        "for i, query in enumerate(test_queries):\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    for j in range(min(3, k)):  # 只显示前3个结果\n",
        "        print(f\"  Match {j+1}: (Score: {D_flat[i][j]:.4f})\")\n",
        "        print(f\"  {corpus[I_flat[i][j]][:100]}...\")\n",
        "\n",
        "# HNSW 索引搜索（快速近似）\n",
        "print(\"\\nHNSW index search results:\")\n",
        "for _ in range(num_runs):\n",
        "    start = time.time()\n",
        "    D_hnsw, I_hnsw = index_hnsw.search(query_embeddings, k)\n",
        "    hnsw_times.append(time.time() - start)\n",
        "\n",
        "avg_hnsw_time = sum(hnsw_times) / len(hnsw_times)\n",
        "print(f\"HNSW index average search time: {avg_hnsw_time*1000:.2f} ms\")\n",
        "print(f\"Speedup vs flat index: {avg_flat_time/avg_hnsw_time:.2f}x\")\n",
        "\n",
        "# 计算与精确搜索的重合度\n",
        "hnsw_overlap = 0\n",
        "for i in range(len(test_queries)):\n",
        "    overlap = len(set(I_flat[i][:k]) & set(I_hnsw[i][:k]))\n",
        "    hnsw_overlap += overlap / k\n",
        "hnsw_overlap /= len(test_queries)\n",
        "\n",
        "print(f\"HNSW average overlap with flat search: {hnsw_overlap:.2%}\")\n",
        "\n",
        "# IVF-PQ 索引搜索（紧凑型）\n",
        "print(\"\\nIVF-PQ index search results:\")\n",
        "index_ivfpq.nprobe = 10  # 搜索时检查的聚类数量\n",
        "for _ in range(num_runs):\n",
        "    start = time.time()\n",
        "    D_ivfpq, I_ivfpq = index_ivfpq.search(query_embeddings, k)\n",
        "    ivfpq_times.append(time.time() - start)\n",
        "\n",
        "avg_ivfpq_time = sum(ivfpq_times) / len(ivfpq_times)\n",
        "print(f\"IVF-PQ index average search time: {avg_ivfpq_time*1000:.2f} ms\")\n",
        "print(f\"Speedup vs flat index: {avg_flat_time/avg_ivfpq_time:.2f}x\")\n",
        "print(f\"Memory usage vs flat index: ~{8/m/bits:.2f}x reduction\")\n",
        "\n",
        "# 计算与精确搜索的重合度\n",
        "ivfpq_overlap = 0\n",
        "for i in range(len(test_queries)):\n",
        "    overlap = len(set(I_flat[i][:k]) & set(I_ivfpq[i][:k]))\n",
        "    ivfpq_overlap += overlap / k\n",
        "ivfpq_overlap /= len(test_queries)\n",
        "\n",
        "print(f\"IVF-PQ average overlap with flat search: {ivfpq_overlap:.2%}\")\n",
        "\n",
        "# 尝试调整 IVF-PQ 参数提高准确性\n",
        "print(\"\\nTrying to improve IVF-PQ accuracy by increasing nprobe...\")\n",
        "index_ivfpq.nprobe = 30  # 增加检查的聚类数量\n",
        "D_ivfpq_improved, I_ivfpq_improved = index_ivfpq.search(query_embeddings, k)\n",
        "\n",
        "# 计算改进后的重合度\n",
        "ivfpq_improved_overlap = 0\n",
        "for i in range(len(test_queries)):\n",
        "    overlap = len(set(I_flat[i][:k]) & set(I_ivfpq_improved[i][:k]))\n",
        "    ivfpq_improved_overlap += overlap / k\n",
        "ivfpq_improved_overlap /= len(test_queries)\n",
        "\n",
        "print(f\"IVF-PQ with nprobe=30 overlap with flat search: {ivfpq_improved_overlap:.2%}\")"
      ],
      "metadata": {
        "id": "pe_YbrY38FaS",
        "outputId": "bbdd7616-b0ab-4199-ec53-fcd94c65b1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing indexes with sample queries...\n",
            "\n",
            "Flat index search results:\n",
            "Flat index average search time: 2.20 ms\n",
            "\n",
            "Query: How does social media affect mental health?\n",
            "  Match 1: (Score: 0.3095)\n",
            "  The Social Cognitive Theory is relevant to health communication. First, the theory deals with cognit...\n",
            "  Match 2: (Score: 0.3061)\n",
            "  Practitioners of magnetic field therapy believe that interactions between the body, the earth, and o...\n",
            "  Match 3: (Score: 0.2739)\n",
            "  Psychiatrists need to be able to take in complex information and synthesize it to reach a conclusion...\n",
            "\n",
            "Query: Best programming languages to learn\n",
            "  Match 1: (Score: 0.3534)\n",
            "  R is a programming language: you do data analysis in R by writing scripts and functions in the R pro...\n",
            "  Match 2: (Score: 0.3201)\n",
            "  An integrated development environment (IDE) is a programming environment that has been packaged as a...\n",
            "  Match 3: (Score: 0.3157)\n",
            "  Furthermore, there is no loss of language ability or language learning ability over time. Age is not...\n",
            "\n",
            "Query: Artificial intelligence applications\n",
            "  Match 1: (Score: 0.2812)\n",
            "  Foreword Smart infrastructure:the future 5 Smart infrastructureprovides the evidencefor informed dec...\n",
            "  Match 2: (Score: 0.2551)\n",
            "  Typically, bots perform tasks that are both simple and structurally repetitive, at a much higher rat...\n",
            "  Match 3: (Score: 0.2533)\n",
            "  Many government agencies use GIS to help in planning and organizing their geographic data. GIS is no...\n",
            "\n",
            "Query: Climate change solutions and mitigation strategies\n",
            "  Match 1: (Score: 0.5062)\n",
            "  Adaptation The Kyoto Protocol, like the Convention, is also designed to assist countries in adapting...\n",
            "  Match 2: (Score: 0.4756)\n",
            "  Main article: Climate change in the United States. The United States is the second largest emitter, ...\n",
            "  Match 3: (Score: 0.4395)\n",
            "  The effects of global warming are the environmental and social changes caused (directly or indirectl...\n",
            "\n",
            "Query: Nutrition advice for athletes performance\n",
            "  Match 1: (Score: 0.5034)\n",
            "  Protein is responsible for rebuilding your muscle tissues after exercise and also plays a minor role...\n",
            "  Match 2: (Score: 0.5014)\n",
            "  General Guidelines. Eat your meal at least three hours before the start of the game. It takes a whil...\n",
            "  Match 3: (Score: 0.4706)\n",
            "  Athletes should not dip below about 250 grams of carbohydrates a day and should strive to get about ...\n",
            "\n",
            "HNSW index search results:\n",
            "HNSW index average search time: 0.27 ms\n",
            "Speedup vs flat index: 8.05x\n",
            "HNSW average overlap with flat search: 88.00%\n",
            "\n",
            "IVF-PQ index search results:\n",
            "IVF-PQ index average search time: 0.22 ms\n",
            "Speedup vs flat index: 10.04x\n",
            "Memory usage vs flat index: ~0.12x reduction\n",
            "IVF-PQ average overlap with flat search: 32.00%\n",
            "\n",
            "Trying to improve IVF-PQ accuracy by increasing nprobe...\n",
            "IVF-PQ with nprobe=30 overlap with flat search: 32.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Save indexes and corpus information\n",
        "print(\"Saving indexes...\")\n",
        "index_dir = os.path.join(PROJECT_PATH, \"models/indexes\")\n",
        "os.makedirs(index_dir, exist_ok=True)\n",
        "\n",
        "# 保存所有索引类型\n",
        "print(\"Saving flat index...\")\n",
        "faiss.write_index(index_flat, os.path.join(index_dir, \"flat_index.faiss\"))\n",
        "\n",
        "print(\"Saving HNSW index...\")\n",
        "faiss.write_index(index_hnsw, os.path.join(index_dir, \"hnsw_index.faiss\"))\n",
        "\n",
        "print(\"Saving IVF-PQ index...\")\n",
        "faiss.write_index(index_ivfpq, os.path.join(index_dir, \"ivfpq_index.faiss\"))\n",
        "\n",
        "# 保存文档数据，用于后续检索时显示结果\n",
        "print(\"Saving corpus texts...\")\n",
        "with open(os.path.join(index_dir, \"corpus_texts.json\"), 'w') as f:\n",
        "    json.dump(corpus, f)\n",
        "\n",
        "# 保存索引配置信息\n",
        "index_config = {\n",
        "    \"flat_index\": {\"type\": \"IndexFlatIP\", \"dimension\": dimension},\n",
        "    \"hnsw_index\": {\"type\": \"IndexHNSWFlat\", \"dimension\": dimension, \"M\": M, \"efConstruction\": ef_construction},\n",
        "    \"ivfpq_index\": {\"type\": \"IndexIVFPQ\", \"dimension\": dimension, \"nlist\": nlist, \"m\": m, \"bits\": bits, \"recommended_nprobe\": 30}\n",
        "}\n",
        "\n",
        "with open(os.path.join(index_dir, \"index_config.json\"), 'w') as f:\n",
        "    json.dump(index_config, f)\n",
        "\n",
        "print(\"\\nAll indexes saved successfully to:\", index_dir)"
      ],
      "metadata": {
        "id": "IhQMgQiQ8VxA",
        "outputId": "ef239637-7005-4f63-e64a-37b1eb0a1d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving indexes...\n",
            "Saving flat index...\n",
            "Saving HNSW index...\n",
            "Saving IVF-PQ index...\n",
            "Saving corpus texts...\n",
            "\n",
            "All indexes saved successfully to: /content/drive/MyDrive/CS6120_project/models/indexes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Create a simple retrieval function for future use\n",
        "def retrieve_documents(query, index_type=\"hnsw\", top_k=5):\n",
        "    \"\"\"\n",
        "    简单的文档检索函数，可以在其他笔记本中重用\n",
        "\n",
        "    参数:\n",
        "    - query: 查询字符串\n",
        "    - index_type: 使用的索引类型 (\"flat\", \"hnsw\", \"ivfpq\")\n",
        "    - top_k: 返回的结果数量\n",
        "\n",
        "    返回:\n",
        "    - 包含文档和相似度分数的列表\n",
        "    \"\"\"\n",
        "    # 编码查询\n",
        "    query_embedding = model.encode([query])\n",
        "    faiss.normalize_L2(query_embedding)\n",
        "\n",
        "    # 选择索引\n",
        "    if index_type == \"flat\":\n",
        "        index = index_flat\n",
        "    elif index_type == \"hnsw\":\n",
        "        index = index_hnsw\n",
        "    elif index_type == \"ivfpq\":\n",
        "        index = index_ivfpq\n",
        "        index.nprobe = 30  # 设置合适的nprobe值\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown index type: {index_type}\")\n",
        "\n",
        "    # 执行搜索\n",
        "    D, I = index.search(query_embedding, top_k)\n",
        "\n",
        "    # 构建结果\n",
        "    results = []\n",
        "    for i in range(top_k):\n",
        "        if i < len(I[0]) and I[0][i] >= 0:  # 确保索引有效\n",
        "            results.append({\n",
        "                \"score\": float(D[0][i]),\n",
        "                \"text\": corpus[I[0][i]],\n",
        "                \"index\": int(I[0][i])\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# 测试检索函数\n",
        "demo_query = \"How to improve productivity while working from home?\"\n",
        "print(\"\\nTesting retrieval function with query:\", demo_query)\n",
        "results = retrieve_documents(demo_query, index_type=\"hnsw\", top_k=3)\n",
        "\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Result {i+1} (Score: {result['score']:.4f}):\")\n",
        "    print(f\"{result['text'][:150]}...\")\n",
        "    print()\n",
        "\n",
        "print(\"Retrieval function is ready for use in other notebooks\")"
      ],
      "metadata": {
        "id": "EKB7UpH38ZH7",
        "outputId": "ccf6f00f-ac43-4542-c5ce-fb8117a66661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing retrieval function with query: How to improve productivity while working from home?\n",
            "Result 1 (Score: 1.4247):\n",
            "7. Buy energy efficient devices: Energy efficient devices cost more up front but over years of use, they’re going to save you money. This hold true fo...\n",
            "\n",
            "Result 2 (Score: 1.4763):\n",
            "Energy efficiency – doing more with less energy – benefits you, your country, and the world. The benefits of energy efficiency are numerous. But the t...\n",
            "\n",
            "Result 3 (Score: 1.4916):\n",
            "Returning to work ■ If you have been off work for a long time, an informal visit during lunchtime or coffee breaks can help you catch up. ■ Your emplo...\n",
            "\n",
            "Retrieval function is ready for use in other notebooks\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}