{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "637989167806477797e65b625c4b141a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7a73b98798d4531a35b465f53c5ac86",
              "IPY_MODEL_7d4616f852cb4458990382a7de9eaa80",
              "IPY_MODEL_3b93dbde13b64b808acd645f5508f45a"
            ],
            "layout": "IPY_MODEL_2d9bb18e5e9f4aff8e15aac1ebe9f05e"
          }
        },
        "d7a73b98798d4531a35b465f53c5ac86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b40c556cf1b449258a400462382cd763",
            "placeholder": "​",
            "style": "IPY_MODEL_8ea841296d8a45dd80e6aba8b4ff1d7f",
            "value": "Batches: 100%"
          }
        },
        "7d4616f852cb4458990382a7de9eaa80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4363aad094ee4d148a9aeacf03a5c7c8",
            "max": 1282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ea47b2ad7f24911ae7cf529a10c5e9a",
            "value": 1282
          }
        },
        "3b93dbde13b64b808acd645f5508f45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0ec3faa6a3408499b68a0561298567",
            "placeholder": "​",
            "style": "IPY_MODEL_a90f7bd8f275494b8cb0c6b6bd5914e9",
            "value": " 1282/1282 [00:57&lt;00:00, 46.17it/s]"
          }
        },
        "2d9bb18e5e9f4aff8e15aac1ebe9f05e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40c556cf1b449258a400462382cd763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea841296d8a45dd80e6aba8b4ff1d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4363aad094ee4d148a9aeacf03a5c7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea47b2ad7f24911ae7cf529a10c5e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0ec3faa6a3408499b68a0561298567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90f7bd8f275494b8cb0c6b6bd5914e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdbc788bf70c41aaaeee8675571d10a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03634fb6881d4d4b9812698793b9bcd5",
              "IPY_MODEL_469e543f5c864c3f8fdca7fdc15def1d",
              "IPY_MODEL_3f8267d41ea94c18a6ff3ce4d6fb83a1"
            ],
            "layout": "IPY_MODEL_c6ee7cd390994139963922f7a9442df7"
          }
        },
        "03634fb6881d4d4b9812698793b9bcd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a97ec1800d4f0c8eb38eb6581e0c9b",
            "placeholder": "​",
            "style": "IPY_MODEL_879b3cee5db04b40a097dd69915f5453",
            "value": "Batches: 100%"
          }
        },
        "469e543f5c864c3f8fdca7fdc15def1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccacda8a4fc74b0d8545217652c2328d",
            "max": 1282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03a1c95457ad4ad895d0c8e35ffd6aef",
            "value": 1282
          }
        },
        "3f8267d41ea94c18a6ff3ce4d6fb83a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b0501e509a48b9a1c9bddfd4ae039f",
            "placeholder": "​",
            "style": "IPY_MODEL_be8f6a1dcdb54f4f93c73c679497240c",
            "value": " 1282/1282 [00:57&lt;00:00, 42.31it/s]"
          }
        },
        "c6ee7cd390994139963922f7a9442df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a97ec1800d4f0c8eb38eb6581e0c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879b3cee5db04b40a097dd69915f5453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccacda8a4fc74b0d8545217652c2328d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a1c95457ad4ad895d0c8e35ffd6aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18b0501e509a48b9a1c9bddfd4ae039f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8f6a1dcdb54f4f93c73c679497240c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Environment Setup"
      ],
      "metadata": {
        "id": "yGAuIxUVqzay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x_r44OpcquEj",
        "outputId": "fe42929d-bf13-4acc-d4d3-36038bebff2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank-bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting pytrec_eval\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pytrec_eval\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp311-cp311-linux_x86_64.whl size=308652 sha256=183cba73871766c49a3c379a7b8d5d786c667c3ca2177e823c230c9d2ff3d0f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/89/42/86aecdb99975f1840c27bc37fdfed72116abcf82e2c9dc76a8\n",
            "Successfully built pytrec_eval\n",
            "Installing collected packages: pytrec_eval\n",
            "Successfully installed pytrec_eval-0.5\n",
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hnswlib) (2.0.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp311-cp311-linux_x86_64.whl size=2389165 sha256=9715d80bec833e2c8cf3d7aca21a77b74c1eeaed84a025f9aa45258446d17c27\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/4e/27/39aebca9958719776e36fada290845a7ef10f053ad70e22ceb\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PROJECT_PATH = \"/content/drive/MyDrive/CS6120_project\"\n",
        "\n",
        "# Environment Setup\n",
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install rank-bm25\n",
        "!pip install datasets\n",
        "!pip install pytrec_eval\n",
        "!pip install hnswlib\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nltk\n",
        "import random\n",
        "import pytrec_eval\n",
        "import hnswlib\n",
        "import faiss\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.notebook import tqdm\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# When using in Colab, you may need to mount your Google Drive (enable if necessary)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # Optional: Disable wandb logging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Prepare Data"
      ],
      "metadata": {
        "id": "FSQBAlYYq5ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_positive_counts(queries, qrels):\n",
        "    \"\"\"\n",
        "    Print the distribution of positive counts for each query to understand the data.\n",
        "    \"\"\"\n",
        "    positive_counts = []\n",
        "    for qid in queries:\n",
        "        if qid in qrels:\n",
        "            positive_counts.append(len(qrels[qid]))\n",
        "        else:\n",
        "            positive_counts.append(0)\n",
        "\n",
        "    counter = Counter(positive_counts)\n",
        "    print(\"Distribution of positive examples (Number of positive examples: Number of queries):\")\n",
        "    for num_pos, num_queries in sorted(counter.items()):\n",
        "        print(f\"{num_pos} positive examples: {num_queries} queries\")\n",
        "\n",
        "    total_queries = len(queries)\n",
        "    no_positive = counter.get(0, 0)\n",
        "    print(f\"\\nTotal number of queries: {total_queries}\")\n",
        "    print(f\"Queries with no positive examples: {no_positive} ({no_positive/total_queries*100:.2f}%)\\n\")\n",
        "\n",
        "def load_msmarco_hf(sample_size=5000, seed=40):\n",
        "    \"\"\"\n",
        "    Load the MS MARCO V1.1 validation set from Hugging Face datasets.\n",
        "    By default, only a sample of 5000 entries is used for testing (modifiable).\n",
        "    Returns: corpus, queries, qrels\n",
        "    \"\"\"\n",
        "    dataset = load_dataset(\"ms_marco\", \"v1.1\")\n",
        "    dev_data = dataset[\"validation\"].shuffle(seed=seed).select(range(sample_size))\n",
        "\n",
        "    queries = {}\n",
        "    corpus = {}\n",
        "    qrels = {}\n",
        "\n",
        "    for example in dev_data:\n",
        "        qid = str(example[\"query_id\"])\n",
        "        query_text = example[\"query\"]\n",
        "        queries[qid] = query_text\n",
        "\n",
        "        passages_info = example[\"passages\"]\n",
        "        passage_texts = passages_info.get(\"passage_text\", [])\n",
        "        is_selecteds = passages_info.get(\"is_selected\", [])\n",
        "\n",
        "        for i, (text, is_sel) in enumerate(zip(passage_texts, is_selecteds)):\n",
        "            doc_id = f\"{qid}_{i}\"\n",
        "            corpus[doc_id] = text\n",
        "            if is_sel == 1:\n",
        "                if qid not in qrels:\n",
        "                    qrels[qid] = {}\n",
        "                qrels[qid][doc_id] = 1\n",
        "\n",
        "    check_positive_counts(queries, qrels)\n",
        "    return corpus, queries, qrels\n",
        "\n",
        "# ========== Load Data ==========\n",
        "corpus, queries, qrels = load_msmarco_hf(sample_size=5000)\n",
        "doc_ids = list(corpus.keys())\n",
        "documents = [corpus[doc_id] for doc_id in doc_ids]\n",
        "print(f\"Loaded {len(corpus)} documents, {len(queries)} queries, {len(qrels)} qrels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u2Pkq--q31r",
        "outputId": "b674ed07-5ade-4697-9fb0-0d37f4595b6c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of positive examples (Number of positive examples: Number of queries):\n",
            "0 positive examples: 186 queries\n",
            "1 positive examples: 4346 queries\n",
            "2 positive examples: 428 queries\n",
            "3 positive examples: 32 queries\n",
            "4 positive examples: 7 queries\n",
            "5 positive examples: 1 queries\n",
            "\n",
            "Total number of queries: 5000\n",
            "Queries with no positive examples: 186 (3.72%)\n",
            "\n",
            "Loaded 40997 documents, 5000 queries, 4814 qrels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Build Indices"
      ],
      "metadata": {
        "id": "cmvbWpDIrAdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 BM25 Index"
      ],
      "metadata": {
        "id": "ZbtS7EqsrE79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bm25(tokenized_corpus, k1=0.9, b=0.6):\n",
        "    \"\"\"\n",
        "    Build and return a BM25Okapi index\n",
        "    \"\"\"\n",
        "    bm25_index = BM25Okapi(tokenized_corpus, k1=k1, b=b)\n",
        "    return bm25_index"
      ],
      "metadata": {
        "id": "KK_ZnhQ-rDRl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Build HNSW Index"
      ],
      "metadata": {
        "id": "IAgZFfNBrOOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hnsw_index(doc_embeddings, ef_construction=200, M=16, ef_search=50):\n",
        "    \"\"\"\n",
        "    Build an HNSW index using hnswlib (space='cosine' indicates cosine distance).\n",
        "    Return the index object.\n",
        "    \"\"\"\n",
        "    num_elements, dim = doc_embeddings.shape\n",
        "    index = hnswlib.Index(space='cosine', dim=dim)\n",
        "    index.init_index(max_elements=num_elements, ef_construction=ef_construction, M=M)\n",
        "    index.add_items(doc_embeddings, ids=np.arange(num_elements))\n",
        "    index.set_ef(ef_search)\n",
        "    return index\n",
        "\n",
        "def build_sbert_hnsw(corpus, model_name_or_path):\n",
        "    \"\"\"\n",
        "    Encode the corpus using the given SBERT model, then build an HNSW index.\n",
        "    Returns: (model, hnsw_index, doc_embeddings)\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(model_name_or_path)\n",
        "    doc_texts = list(corpus.values())\n",
        "    doc_embeddings = model.encode(doc_texts, convert_to_numpy=True, show_progress_bar=True)\n",
        "    hnsw_index = build_hnsw_index(doc_embeddings)\n",
        "    return model, hnsw_index, doc_embeddings"
      ],
      "metadata": {
        "id": "bK8DppBmrQ1m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Document Rretrieval Methods"
      ],
      "metadata": {
        "id": "3LU6WMXkrQfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_retrieve(query, bm25_index, doc_ids, k=10):\n",
        "    \"\"\"\n",
        "    BM25 retrieval: Return the top k doc_ids and scores.\n",
        "    \"\"\"\n",
        "    query_tokens = word_tokenize(query.lower())\n",
        "    bm25_scores = bm25_index.get_scores(query_tokens)\n",
        "    top_indices = np.argsort(bm25_scores)[::-1][:k]\n",
        "    ranked_doc_ids = [doc_ids[i] for i in top_indices]\n",
        "    scores = bm25_scores[top_indices]\n",
        "    return ranked_doc_ids, scores\n",
        "\n",
        "def hnsw_retrieve(query, model, hnsw_index, doc_ids, top_k=10):\n",
        "    \"\"\"\n",
        "    HNSW + SBERT vector retrieval: Return the top k doc_ids and scores.\n",
        "    \"\"\"\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    labels, distances = hnsw_index.knn_query(query_embedding, k=top_k)\n",
        "    retrieved_ids = [doc_ids[i] for i in labels[0]]\n",
        "    # Since cosine distance = 1 - cosine_similarity, the similarity score is computed as: score = 1 - distance\n",
        "    scores = [1 - d for d in distances[0]]\n",
        "    return retrieved_ids, scores\n",
        "\n",
        "def normalize_scores(scores):\n",
        "    \"\"\"\n",
        "    Simply normalize the scores to [0, 1] to avoid large discrepancies between different retrieval methods.\n",
        "    \"\"\"\n",
        "    min_val = np.min(scores)\n",
        "    max_val = np.max(scores)\n",
        "    return (scores - min_val) / (max_val - min_val + 1e-8)\n",
        "\n",
        "def hybrid_retrieve(query, bm25_index, hnsw_index, model, doc_ids, top_k=10, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Hybrid retrieval: Fuse the scores from BM25 and HNSW (SBERT) using:\n",
        "    final_score = alpha * bm25_score_norm + (1 - alpha) * hnsw_score_norm\n",
        "    \"\"\"\n",
        "    candidate_k = top_k * 5  # A larger candidate set can be used for fusion\n",
        "\n",
        "    # Perform BM25 and HNSW retrieval separately\n",
        "    bm25_ids, bm25_scores = bm25_retrieve(query, bm25_index, doc_ids, k=candidate_k)\n",
        "    hnsw_ids, hnsw_scores = hnsw_retrieve(query, model, hnsw_index, doc_ids, top_k=candidate_k)\n",
        "\n",
        "    bm25_norm = normalize_scores(np.array(bm25_scores))\n",
        "    hnsw_norm = normalize_scores(np.array(hnsw_scores))\n",
        "\n",
        "    candidate_set = set(bm25_ids) | set(hnsw_ids)\n",
        "    bm25_dict = dict(zip(bm25_ids, bm25_norm))\n",
        "    hnsw_dict = dict(zip(hnsw_ids, hnsw_norm))\n",
        "\n",
        "    combined_scores = {}\n",
        "    for docid in candidate_set:\n",
        "        score_bm25 = bm25_dict.get(docid, 0.0)\n",
        "        score_hnsw = hnsw_dict.get(docid, 0.0)\n",
        "        combined_scores[docid] = alpha * score_bm25 + (1 - alpha) * score_hnsw\n",
        "\n",
        "    # Sort and select top k candidates\n",
        "    ranked_candidates = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "    ranked_doc_ids = [docid for docid, score in ranked_candidates]\n",
        "    ranked_scores = [score for docid, score in ranked_candidates]\n",
        "    return ranked_doc_ids, ranked_scores"
      ],
      "metadata": {
        "id": "d4O_mwklrXfs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluation"
      ],
      "metadata": {
        "id": "DV0uSDSirbFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Build Run"
      ],
      "metadata": {
        "id": "uFMHQPL9rdzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_run_bm25(queries, bm25_index, doc_ids, top_k=100):\n",
        "    \"\"\"\n",
        "    For all queries, perform BM25 retrieval.\n",
        "    Returns a run: {qid: {docid: score}}\n",
        "    \"\"\"\n",
        "    run = {}\n",
        "    for qid, query in queries.items():\n",
        "        ranked_doc_ids, scores = bm25_retrieve(query, bm25_index, doc_ids, k=top_k)\n",
        "        run[qid] = {docid: float(score) for docid, score in zip(ranked_doc_ids, scores)}\n",
        "    return run\n",
        "\n",
        "def build_run_hnsw(queries, model, hnsw_index, doc_ids, top_k=100):\n",
        "    \"\"\"\n",
        "    For all queries, perform HNSW+SBERT retrieval.\n",
        "    Returns a run: {qid: {docid: score}}\n",
        "    \"\"\"\n",
        "    run = {}\n",
        "    for qid, query in queries.items():\n",
        "        ranked_doc_ids, scores = hnsw_retrieve(query, model, hnsw_index, doc_ids, top_k=top_k)\n",
        "        run[qid] = {docid: float(score) for docid, score in zip(ranked_doc_ids, scores)}\n",
        "    return run\n",
        "\n",
        "def build_run_hybrid(queries, bm25_index, hnsw_index, model, doc_ids, top_k=100, alpha=0.5):\n",
        "    \"\"\"\n",
        "    For all queries, perform Hybrid retrieval.\n",
        "    \"\"\"\n",
        "    run = {}\n",
        "    for qid, query in queries.items():\n",
        "        ranked_doc_ids, scores = hybrid_retrieve(query, bm25_index, hnsw_index, model, doc_ids, top_k=top_k, alpha=alpha)\n",
        "        run[qid] = {docid: float(score) for docid, score in zip(ranked_doc_ids, scores)}\n",
        "    return run\n"
      ],
      "metadata": {
        "id": "dcorWFTDrcuF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Evaluate Runs"
      ],
      "metadata": {
        "id": "RAc2ZPFLrkat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mrr_at_k(run, qrels, k=100):\n",
        "    \"\"\"\n",
        "    Compute MRR@k\n",
        "    run: {qid: {docid: score}}\n",
        "    qrels: {qid: {docid: relevance}}\n",
        "    \"\"\"\n",
        "    total_rr = 0.0\n",
        "    num_queries = 0\n",
        "\n",
        "    for qid, relevant_docs in qrels.items():\n",
        "        if qid not in run:\n",
        "            continue\n",
        "\n",
        "        # Sort the documents by score in descending order and take the top k\n",
        "        sorted_docs = sorted(run[qid].items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "\n",
        "        rr = 0.0\n",
        "        for rank, (doc_id, score) in enumerate(sorted_docs, start=1):\n",
        "            # Treat relevance > 0 as relevant\n",
        "            if doc_id in relevant_docs and relevant_docs[doc_id] > 0:\n",
        "                rr = 1.0 / rank\n",
        "                break\n",
        "        total_rr += rr\n",
        "        num_queries += 1\n",
        "\n",
        "    return total_rr / num_queries if num_queries else 0.0\n",
        "\n",
        "def compute_recall_at_k(run, qrels, k=100):\n",
        "    \"\"\"\n",
        "    Compute Recall@k\n",
        "    \"\"\"\n",
        "    total_recall = 0.0\n",
        "    num_queries_with_rels = 0\n",
        "\n",
        "    for qid, rel_docs in qrels.items():\n",
        "        relevant_docs = {doc_id for doc_id, rel in rel_docs.items() if rel > 0}\n",
        "        if not relevant_docs:\n",
        "            # Skip queries with no relevant documents or count as 0\n",
        "            continue\n",
        "\n",
        "        if qid not in run:\n",
        "            num_queries_with_rels += 1\n",
        "            continue\n",
        "\n",
        "        sorted_docs = sorted(run[qid].items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "        top_k_docs = {doc_id for doc_id, score in sorted_docs}\n",
        "        hit_count = len(relevant_docs & top_k_docs)\n",
        "        recall_q = hit_count / len(relevant_docs)\n",
        "\n",
        "        total_recall += recall_q\n",
        "        num_queries_with_rels += 1\n",
        "\n",
        "    return total_recall / num_queries_with_rels if num_queries_with_rels else 0.0\n",
        "\n",
        "def evaluate_run(run, qrels):\n",
        "    \"\"\"\n",
        "    Evaluate a run and return various metrics.\n",
        "    \"\"\"\n",
        "    # Use pytrec_eval to evaluate NDCG and MAP\n",
        "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'ndcg', 'map'})\n",
        "    results = evaluator.evaluate(run)\n",
        "\n",
        "    avg_ndcg = sum(d.get('ndcg', 0) for d in results.values()) / len(results)\n",
        "    avg_map = sum(d.get('map', 0) for d in results.values()) / len(results)\n",
        "    mrr_100 = compute_mrr_at_k(run, qrels, k=100)\n",
        "    recall_100 = compute_recall_at_k(run, qrels, k=100)\n",
        "\n",
        "    return {\n",
        "        'ndcg': avg_ndcg,\n",
        "        'map': avg_map,\n",
        "        'mrr@100': mrr_100,\n",
        "        'recall@100': recall_100\n",
        "    }"
      ],
      "metadata": {
        "id": "ewpMjXE-rn9I"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Results"
      ],
      "metadata": {
        "id": "-yLEbNz6rs_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== 1) stsb_finetuned_sbert_model + HNSW ==========\n",
        "model_path_1 = \"/content/drive/MyDrive/CS6120_project/model/stsb_finetuned_model\"\n",
        "model_1, hnsw_1, doc_emb_1 = build_sbert_hnsw(corpus, model_path_1)\n",
        "run_1 = build_run_hnsw(queries, model_1, hnsw_1, doc_ids, top_k=100)\n",
        "results_1 = evaluate_run(run_1, qrels)\n",
        "\n",
        "# ========== 2) msmarco_stsb_finetuned_sbert_model + HNSW ==========\n",
        "model_path_2 = \"/content/drive/MyDrive/CS6120_project/model/msmarco_stsb_finetuned_model\"\n",
        "model_2, hnsw_2, doc_emb_2 = build_sbert_hnsw(corpus, model_path_2)\n",
        "run_2 = build_run_hnsw(queries, model_2, hnsw_2, doc_ids, top_k=100)\n",
        "results_2 = evaluate_run(run_2, qrels)\n",
        "\n",
        "# ========== 3) BM25 (k1=0.9, b=0.6) ==========\n",
        "tokenized_corpus = [word_tokenize(doc.lower()) for doc in documents]\n",
        "bm25_1 = build_bm25(tokenized_corpus, k1=0.9, b=0.6)\n",
        "run_3 = build_run_bm25(queries, bm25_1, doc_ids, top_k=100)\n",
        "results_3 = evaluate_run(run_3, qrels)\n",
        "\n",
        "# ========== 4) BM25 (k1=1.2, b=0.75) ==========\n",
        "bm25_2 = build_bm25(tokenized_corpus, k1=1.2, b=0.75)\n",
        "run_4 = build_run_bm25(queries, bm25_2, doc_ids, top_k=100)\n",
        "results_4 = evaluate_run(run_4, qrels)\n",
        "\n",
        "# ========== 5) msmarco_stsb_finetuned_sbert_model + Hybrid ==========\n",
        "# Here we fuse BM25 (1.2, 0.75) with msmarco_stsb_finetuned_sbert_model\n",
        "run_5 = build_run_hybrid(queries, bm25_2, hnsw_2, model_2, doc_ids, top_k=100, alpha=0.5)\n",
        "results_5 = evaluate_run(run_5, qrels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "637989167806477797e65b625c4b141a",
            "d7a73b98798d4531a35b465f53c5ac86",
            "7d4616f852cb4458990382a7de9eaa80",
            "3b93dbde13b64b808acd645f5508f45a",
            "2d9bb18e5e9f4aff8e15aac1ebe9f05e",
            "b40c556cf1b449258a400462382cd763",
            "8ea841296d8a45dd80e6aba8b4ff1d7f",
            "4363aad094ee4d148a9aeacf03a5c7c8",
            "3ea47b2ad7f24911ae7cf529a10c5e9a",
            "ea0ec3faa6a3408499b68a0561298567",
            "a90f7bd8f275494b8cb0c6b6bd5914e9",
            "cdbc788bf70c41aaaeee8675571d10a3",
            "03634fb6881d4d4b9812698793b9bcd5",
            "469e543f5c864c3f8fdca7fdc15def1d",
            "3f8267d41ea94c18a6ff3ce4d6fb83a1",
            "c6ee7cd390994139963922f7a9442df7",
            "c0a97ec1800d4f0c8eb38eb6581e0c9b",
            "879b3cee5db04b40a097dd69915f5453",
            "ccacda8a4fc74b0d8545217652c2328d",
            "03a1c95457ad4ad895d0c8e35ffd6aef",
            "18b0501e509a48b9a1c9bddfd4ae039f",
            "be8f6a1dcdb54f4f93c73c679497240c"
          ]
        },
        "id": "pIzK4GosruZu",
        "outputId": "249097cc-2bb5-4427-9c14-08d9b0da9a14"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "637989167806477797e65b625c4b141a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdbc788bf70c41aaaeee8675571d10a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_all = {\n",
        "    \"stsb_finetuned_sbert_model + HNSW\": results_1,\n",
        "    \"msmarco_stsb_finetuned_sbert_model + HNSW\": results_2,\n",
        "    \"BM25 (0.9, 0.6)\": results_3,\n",
        "    \"BM25 (1.2, 0.75)\": results_4,\n",
        "    \"msmarco_stsb_finetuned + Hybrid\": results_5\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(results_all).T  # Rows represent methods, columns represent metrics\n",
        "\n",
        "# For a more visually pleasing output and to control the number of decimal places\n",
        "df_rounded = df.round(4)\n",
        "print(\"\\n=== Final Results (rounded to 4 decimals) ===\")\n",
        "print(df_rounded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRu_f4tGsFfJ",
        "outputId": "8d21b8d3-ce61-4a4f-9f04-ac077c1f2c70"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Final Results (rounded to 4 decimals) ===\n",
            "                                             ndcg     map  mrr@100  recall@100\n",
            "stsb_finetuned_sbert_model + HNSW          0.3390  0.2308   0.2389      0.7379\n",
            "msmarco_stsb_finetuned_sbert_model + HNSW  0.5588  0.4309   0.4384      0.9749\n",
            "BM25 (0.9, 0.6)                            0.5079  0.3842   0.3917      0.9225\n",
            "BM25 (1.2, 0.75)                           0.5063  0.3819   0.3893      0.9231\n",
            "msmarco_stsb_finetuned + Hybrid            0.5767  0.4488   0.4559      0.9891\n"
          ]
        }
      ]
    }
  ]
}