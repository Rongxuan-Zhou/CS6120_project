## Project Overview

This project is an enhanced social media short-text retrieval system using a hybrid retrieval architecture combining SBERT and BM25. It leverages GPU-accelerated FAISS HNSW indexes to achieve extremely low latency (0.02ms) and high throughput (1,000 QPS).

_Last Updated: March 16, 2025_

## Tech Stack

- Primary Language: Python
- Core Technologies: SBERT, BM25, FAISS, GPU Acceleration
- Supporting Tools: Bayesian Optimization, Containerized Deployment

## Coding Standards

### Naming Conventions

- Classes: PascalCase (e.g., `DynamicWeightRanker`)
- Functions and Methods: snake_case (e.g., `normalize`)
- Constants: UPPER_SNAKE_CASE
- Variables: snake_case

### Code Structure

- Clearly defined responsibilities for each module
- Use type hints to enhance readability
- Critical functions must include docstrings in the following format:

```python
def function_name(param1, param2):
    """
    Brief description of the function.

    Args:
        param1: Description of parameter 1.
        param2: Description of parameter 2.

    Returns:
        Description of the return value.

    Raises:
        Possible exceptions raised.
    """
```

### Commenting Standards

- Detailed comments required for complex algorithms
- Include links to referenced research papers in comments
- Annotate time/space complexity for performance-critical sections

## Project-Specific Rules

### Vector Search Optimization

- Implement IVF_PQ quantization with 4x compression ratio
- Convert vector storage from fp32 to fp16 to reduce memory usage by 50%
- Monitor real-time GPU memory usage, especially for scenarios involving 10 million documents

### Evaluation Standards

- MRR@10 â‰¥ 0.72 (top 20% on MS MARCO Document Ranking Leaderboard)
- Support peak traffic of up to 5,000 QPS
- Conduct domain-specific performance evaluations across BEIR's 18 tasks, with particular attention to finance and medical domains

### Fallback Strategy

- Prepare RoBERTa-base as a degraded alternative to SBERT (2x speed-up with a 5% accuracy trade-off)
- Implement a dynamic weighting strategy that adjusts BM25 and semantic scores based on query type using logistic regression classifiers.

## Reference Resources

- [ColBERTv2 Paper](https://arxiv.org/abs/2112.01488)
- [FAISS Optimization Guide](https://github.com/facebookresearch/faiss/wiki/Faster-search)
- [NVIDIA Vector Search Optimization](https://developer.nvidia.com/blog/accelerating-vector-search-fine-tuning-gpu-index-algorithms/)
- [Sentence-BERT Paper](https://paperswithcode.com/paper/sentence-bert-sentence-embeddings-using)

## Implementation Roadmap Reference

The project is divided into four phases:

| Phase                 | Duration | Key Tasks                                                                                         |
|-----------------------|----------|---------------------------------------------------------------------------------------------------|
| 1. Data Preparation   | 2 weeks  | Social media noise handling using techniques from [EnCBP](https://arxiv.org/abs/2203.14498)       |
| 2. Model Development  | 2 weeks  | SBERT fine-tuning with Twitter dataset; Bayesian optimization for parameter tuning                |
| 3. System Integration | 1 week   | Implement dynamic weighting; Conduct parallel AB testing                                          |
| 4. Evaluation & Optimization | 1 week   | Stress testing (5,000 QPS peak); Domain-specific performance evaluation on BEIR's tasks |

Each pull request should clearly indicate the corresponding project phase and key tasks.

## Risk Management

Please pay attention to identified risks in the project plan, especially:

| Module            | Risk                                 | Mitigation Strategy                                                                                             |
|-------------------|--------------------------------------|------------------------------------------------------------------------------------------------------------------|
| Semantic Encoding | Domain drift (e.g., internet slang)  | Fine-tune SBERT on Twitter dataset using methods from [Sentence-BERT paper](https://paperswithcode.com/paper/sentence-bert-sentence-embeddings-using) |
| Hybrid Ranking    | Inefficient parameter tuning         | Replace grid search with Bayesian optimization (40% time saving)                                                 |
| Deployment        | Cold start latency                   | Implement container pre-warming on GPU instances                                                                 |

---